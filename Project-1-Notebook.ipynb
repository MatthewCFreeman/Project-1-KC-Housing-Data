{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatiron Data Science Project 1: The King County Housing Data Set\n",
    "### Matthew Freeman -- Work Beginning on 3rd March 2019\n",
    "\n",
    "#### The project will use data science methods in the Python 3 language to explore the King County Housing Data Set. This data set contains real data points on house sale prices within King County, WA, U.S.A. and some house details which may or may not have influenced pricing. This investigation shall be using a multivariate linear regression to try to create a model which can predict house prices from these added details, and will also attempt to answer three questions posed by myself below.\n",
    "\n",
    "### Question A: What can be inferred about this data set from its exposure to misfitting?\n",
    "\n",
    "### Question B: Where are the higher valued houses in King County located AND how best can I improve my model with location related data?\n",
    "\n",
    "### Question C: How much more accurate and reliable can a price prediction be based on a multivariate linear regression rather than the single most correlated variable?\n",
    "\n",
    "     \n",
    "#### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "#### This investigation will roughly follow the OSEMN data science process, with some iteration and backward steps being employed where investigation requires it. \n",
    "#### This means that I will be trying to carry out the investigation in five steps. First, I shall Obtain the data: gathering whatever is needed from the required sources. Second, I shall Scrub the data set: finding missing or incorrectly labelled data points and preparing the data for the best analysis possible. Third, I shall Explore the dataset: looking for patterns and anomalies across statistical distributions and correlations which can inform my investigation strategy. Fourth, I shall Model the data: iterating different models to settle on one with the most significant predictive power and using appropriate methods to check validity. Fifth, and finally, I shall iNterpret the results of our investigation: I shall discuss their predictive reliability and  their success in answering the questions.\n",
    "\n",
    "#### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Obtain\n",
    "\n",
    "##### Aims: Import libraries and functions to be used throughout investigation; detail kernel used; apply any plotting settings; and most importantly, store data set in a dataframe for easy manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This code is written in Python 3 using the \"learn-env\" kernel.\n",
    "# Import pandas for dataframe usage.\n",
    "import pandas as pd\n",
    "# Import matplotlib.pyplot for basic plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "# Import seaborn for advanced plotting and plot styling.\n",
    "import seaborn as sns\n",
    "# Import numpy for mathematical functions.\n",
    "import numpy as np\n",
    "# Import statsmodels for statistics functions.\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Set plotting style and appearance magic.\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data set is saved as kc_house_data.csv within this directory. I shall read it into a Pandas dataframe.\n",
    "kc_df = pd.read_csv('kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Scrub\n",
    "\n",
    "##### Aims: Look through data for missing values, mislabelled data, poorly captured data points or categories, etc.; seek most appropriate solution; fix data as best possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  10/13/2014  221900.0         3       1.00         1180   \n",
       "1  6414100192   12/9/2014  538000.0         3       2.25         2570   \n",
       "2  5631500400   2/25/2015  180000.0         2       1.00          770   \n",
       "3  2487200875   12/9/2014  604000.0         4       3.00         1960   \n",
       "4  1954400510   2/18/2015  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650     1.0         NaN   0.0     ...          7        1180   \n",
       "1      7242     2.0         0.0   0.0     ...          7        2170   \n",
       "2     10000     1.0         0.0   0.0     ...          6         770   \n",
       "3      5000     1.0         0.0   0.0     ...          7        1050   \n",
       "4      8080     1.0         0.0   0.0     ...          8        1680   \n",
       "\n",
       "   sqft_basement yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0            0.0     1955           0.0    98178  47.5112 -122.257   \n",
       "1          400.0     1951        1991.0    98125  47.7210 -122.319   \n",
       "2            0.0     1933           NaN    98028  47.7379 -122.233   \n",
       "3          910.0     1965           0.0    98136  47.5208 -122.393   \n",
       "4            0.0     1987           0.0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This data set is small enough in size that I am confident it would be possible to get a good feel for it\n",
    "# by displaying the first few rows.\n",
    "kc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 21 columns):\n",
      "id               21597 non-null int64\n",
      "date             21597 non-null object\n",
      "price            21597 non-null float64\n",
      "bedrooms         21597 non-null int64\n",
      "bathrooms        21597 non-null float64\n",
      "sqft_living      21597 non-null int64\n",
      "sqft_lot         21597 non-null int64\n",
      "floors           21597 non-null float64\n",
      "waterfront       19221 non-null float64\n",
      "view             21534 non-null float64\n",
      "condition        21597 non-null int64\n",
      "grade            21597 non-null int64\n",
      "sqft_above       21597 non-null int64\n",
      "sqft_basement    21597 non-null object\n",
      "yr_built         21597 non-null int64\n",
      "yr_renovated     17755 non-null float64\n",
      "zipcode          21597 non-null int64\n",
      "lat              21597 non-null float64\n",
      "long             21597 non-null float64\n",
      "sqft_living15    21597 non-null int64\n",
      "sqft_lot15       21597 non-null int64\n",
      "dtypes: float64(8), int64(11), object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Now let's check the column data types and sizes, as well as see all the variables available to us.\n",
    "kc_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. There are 21 columns and I can see already that some are not in the correct data type or are shorter than others. Let's go through these columns in detail.\n",
    "\n",
    "id: This variable relates to numbers identifying the property sold. As we have no key relating to these properties id codes, or any knowledge of methodology in assigning these id codes, we can remove this column as it is useless to us. We can simply rely on the pandas index for this dataframe for such a purpose.\n",
    "\n",
    "date: This variable contains dates, entered in a text format. Dates can be most easily understood by python if they are reformatted into a purely numerical date format, which pandas functionality exists to allow. There may likely also be incorrectly written dates in this column which we must check for and deal with as best as possible.\n",
    "\n",
    "price: This variable contains assumedly USD sale prices for the properties. They are mostly rounded to 1 decimal place which is an odd choice when most properties have a price rounded to the nearest hundred or thousand dollars anyway. After better understanding how erroneous data points may be included it would be preferable to round up to the nearest dollar as it would look neater in plots and a single decimal point is no more correct a rounding choice. \n",
    "This variable is the PREDICTION TARGET and should also be copied into a separate pandas series for later use.\n",
    "\n",
    "bedrooms: This variable contains low integers representing the number of bedrooms in the house sold. Thankfully the data type of the series seems appropriate for this. As long as there are no mistakenly high or low numbers this may be as accurate as possible.\n",
    "\n",
    "bathrooms: This variable should be the same as the bedrooms variable, but for the number of bathrooms. Sadly, the series data type seems to be including more than just integers as it is a floating point. This should be fixed.\n",
    "\n",
    "sqft_living, sqft_lot: These variables are for the square foot area of the living space and lot, respectively. They are recorded as appropriately sized integers so they should probably not require much scrubbing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix columns 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix columns 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore\n",
    "\n",
    "##### Aims: Check statistical measures of data set variables, analyse distributions of data set variables, locate anomalies, and consider different uses for variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model\n",
    "\n",
    "##### Aims: Create multivariate linear regression model, iterating for best variables to use or avoid, best split ratio to use, and check for validity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Interpret\n",
    "\n",
    "##### Aims: Discuss predictive power and reliability of model, answer questions, debate level of success in answering questions, and discuss proposals for future improvements to the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
